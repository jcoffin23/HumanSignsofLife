{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Exercise #05 ##\n",
    "\n",
    "### Load the Common Imports ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.3\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Input as Input\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras import layers\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "# load the MNIST data set, which already splits into training and test sets.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a Sample Image ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape and Scale the Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_x, img_y = 28, 28\n",
    "#Reshape the data into a 4d tensor\n",
    "x_train = x_train.reshape(x_train.shape[0], img_x, img_y, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_x, img_y, 1)\n",
    "input_shape = (img_x, img_y, 1)\n",
    "\n",
    "# convert the data to the right type\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "print(y_train[0].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert class vectors to binary class matrices ###\n",
    "\n",
    "This is the one to use with the `categorical_crossentropy` loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_classes = 10 # Number of classes\n",
    "if y_train[0].shape != ():\n",
    "    print('Did not increase y_train') #Put this so that data doesnt grow a dim every time it runs\n",
    "else:\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "x=y_train[0].shape \n",
    "print(x)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Example ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 28, 32)            928       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 28, 32)            1056      \n",
      "=================================================================\n",
      "Total params: 1,984\n",
      "Trainable params: 1,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(28,28,)))\n",
    "model.add(Dense(32,))\n",
    "model.add(Dense(32))\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion -  Shape of Network\n",
    "The network designed above has 2 dense layers. The output size of the layers is (none,28,32). The layer size is (batch size, size of map). In this case the Batch size is not known until training and each feature map will be 28x32 since each ense layer has 32 Neurons which each output being 28x32. This is true for both layers. This creates a total of 1984 params. Since there is not activation function applied, then no activation is done, ie this is linear and thus the activation looks like a(x) = x. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment ###\n",
    "Construct a network to perform logistic regression on the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A More Complicated Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1025000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,087,106\n",
      "Trainable params: 1,087,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_classes=10\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),padding='same'))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model ###\n",
    "\n",
    "Here is a compilation of a simple model for recognition of images in the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Simple Model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(28,28,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "#\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Learning Parameters ###\n",
    "\n",
    "Put in your own numbers.  These are simply placeholders and not necessarily the right numbers to use.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Character Recognition ##\n",
    "Assignment to design one-hidden layer and two-hidden layer MLPs using different structures, and do the same for CNNs.  See assignment for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100  # Set the batch size\n",
    "epochs = 10 # Set the number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.8224 - val_loss: 0.2744 - val_accuracy: 0.9200\n",
      "Epoch 2/10\n",
      "402/402 [==============================] - 1s 3ms/step - loss: 0.3467 - accuracy: 0.8953 - val_loss: 0.2085 - val_accuracy: 0.9406\n",
      "Epoch 3/10\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2783 - accuracy: 0.9154 - val_loss: 0.1733 - val_accuracy: 0.9488\n",
      "Epoch 4/10\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2436 - accuracy: 0.9259 - val_loss: 0.1582 - val_accuracy: 0.9520\n",
      "Epoch 5/10\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2173 - accuracy: 0.9340 - val_loss: 0.1428 - val_accuracy: 0.9577\n",
      "Epoch 6/10\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9391 - val_loss: 0.1260 - val_accuracy: 0.9625\n",
      "Epoch 7/10\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1808 - accuracy: 0.9453 - val_loss: 0.1194 - val_accuracy: 0.9631\n",
      "Epoch 8/10\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1723 - accuracy: 0.9465 - val_loss: 0.1196 - val_accuracy: 0.9636\n",
      "Epoch 9/10\n",
      "402/402 [==============================] - 1s 3ms/step - loss: 0.1551 - accuracy: 0.9513 - val_loss: 0.1111 - val_accuracy: 0.9668\n",
      "Epoch 10/10\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1476 - accuracy: 0.9532 - val_loss: 0.1033 - val_accuracy: 0.9687\n",
      "Test loss: 0.09211120754480362\n",
      "Test accuracy: 0.9710000157356262\n"
     ]
    }
   ],
   "source": [
    "# One Hidden Layer\n",
    "\n",
    "\n",
    "initializer = keras.initializers.RandomNormal(mean=0., stddev=5.)\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(28,28,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate = .5,seed = 7))\n",
    "model.add(Dense(100, activation='relu',kernel_initializer=None,kernel_constraint=None))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "#\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.33,\n",
    "          callbacks=None) #[history])\n",
    "\n",
    "#\n",
    "# Print what is in hist.history\n",
    "#\n",
    "#print('history contains: ', hist.history)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion about One Hidden Layer\n",
    "\n",
    "The structure is simple, an input layer, then a flatten, then the Dense hidden layer followed by softmax output layer. \n",
    "\n",
    "With the single hidden layer the only parameters to play with are the ones of the Dense layer. The activation funtion, bias, kernel initialization, bias initialization, kernel regularizer, and constriaints were some that I exaimed. No significant difference was found for different activation functions, but ReLU seems to be the best. The bias and Initialization seem to only make the system take longer to reach the same CV score, so for that reason I will not be changing any of the initalizer or bias settings moving forward. The most important is the number of Neurons. I started with a small number, 10, and acheived an cv accuracy rate of 92% from 10 epochs. Upping this to 1000 neurons, which decreased the CV accuracy slightly. The big jump in accuracy came with the addition of the ReLu activation function which did not increase accuracy for 10 neurons but upped the 1000 nenurons to 97.3% vladiation. Doubling it to 2000 increases the processing time signicantly but provides little to no benefit. This is a diminishing return and to increase resutls we must look eslewhere.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion About Two Hidden Layer\n",
    "\n",
    "The NN with Two hidden Layers increases the amount of flexibility, but also ups the complexity. Leaving the second layer as a 1000 neuron ReLu layer, which worked well in the first case, the only thing to configure is the first Dense layer. To start I set this to have 10 neurons and with a ReLU activation function. This netted no increase in accuracy with a CV score of about 97.46% after 10 epochs. Getting rid of the activation function lowerd the CV score to 97.2% So it will be used for both layers. \n",
    "\n",
    "Upping the neurons in the first layer increased the parameters to be learned from 8 million to 80 million but upped the CV score back to 97.48%, but at 30 minutes training time as opposed to 3 minutes in the single hidden layer case above. Adding a BatchNormalization layer did not seem to help, but did seem to make things worse. The same is true for a dropout layer. A two hidden layer seems like it would need to have many many neuronsto get close to 99% CV score. Two 1000 neuron dense layers might work, but that would take several hours to run, so I am not going to show the results and instead the base line for Hidden layer NN's will be a CV score of 97.48% with a test accuracy of 97.2% \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "402/402 [==============================] - 47s 117ms/step - loss: 0.3791 - accuracy: 0.8897 - val_loss: 0.5693 - val_accuracy: 0.8716\n",
      "Epoch 2/10\n",
      "402/402 [==============================] - 48s 119ms/step - loss: 0.2900 - accuracy: 0.9169 - val_loss: 0.2939 - val_accuracy: 0.9189\n",
      "Epoch 3/10\n",
      "402/402 [==============================] - 48s 120ms/step - loss: 0.2708 - accuracy: 0.9231 - val_loss: 0.2974 - val_accuracy: 0.9155\n",
      "Epoch 4/10\n",
      "402/402 [==============================] - 50s 126ms/step - loss: 0.2465 - accuracy: 0.9297 - val_loss: 0.2732 - val_accuracy: 0.9278\n",
      "Epoch 5/10\n",
      "402/402 [==============================] - 49s 122ms/step - loss: 0.2255 - accuracy: 0.9364 - val_loss: 0.2646 - val_accuracy: 0.9248\n",
      "Epoch 6/10\n",
      "402/402 [==============================] - 48s 120ms/step - loss: 0.2078 - accuracy: 0.9386 - val_loss: 0.2656 - val_accuracy: 0.9276\n",
      "Epoch 7/10\n",
      "402/402 [==============================] - 47s 118ms/step - loss: 0.1916 - accuracy: 0.9432 - val_loss: 0.2691 - val_accuracy: 0.9271\n",
      "Epoch 8/10\n",
      "402/402 [==============================] - 47s 116ms/step - loss: 0.1836 - accuracy: 0.9461 - val_loss: 0.2582 - val_accuracy: 0.9286\n",
      "Epoch 9/10\n",
      "402/402 [==============================] - 47s 116ms/step - loss: 0.1694 - accuracy: 0.9505 - val_loss: 0.2864 - val_accuracy: 0.9260\n",
      "Epoch 10/10\n",
      "402/402 [==============================] - 47s 116ms/step - loss: 0.1651 - accuracy: 0.9503 - val_loss: 0.2830 - val_accuracy: 0.9199\n",
      "Test loss: 0.2745872139930725\n",
      "Test accuracy: 0.92330002784729\n"
     ]
    }
   ],
   "source": [
    "# Two Hidden Layer\n",
    "\n",
    "\n",
    "initializer = keras.initializers.RandomNormal(mean=0., stddev=5.)\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(28,28,1)))\n",
    "\n",
    "model.add(Dense(1000,activation='relu'))\n",
    "model.add(BatchNormalization(axis=3,trainable=True))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "#\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.33,\n",
    "          callbacks=None) #[history])\n",
    "\n",
    "#\n",
    "# Print what is in hist.history\n",
    "#\n",
    "#print('history contains: ', hist.history)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_68 (Conv2D)           (None, 24, 24, 64)        1664      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_61 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 1000)              2049000   \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 2,266,114\n",
      "Trainable params: 2,265,858\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN\n",
    "\n",
    "\n",
    "\n",
    "num_classes=10\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(28,28,1)))\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "model.add(Dropout(rate = .5,seed = 7))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),padding='same'))\n",
    "model.add(Conv2D(128, (5, 5), activation='relu'))\n",
    "model.add(BatchNormalization(axis=3,trainable=True))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 45s 1s/step - loss: 0.5888 - accuracy: 0.8553 - val_loss: 1.7602 - val_accuracy: 0.8786\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 46s 1s/step - loss: 0.0684 - accuracy: 0.9787 - val_loss: 1.5578 - val_accuracy: 0.9684\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 47s 1s/step - loss: 0.0389 - accuracy: 0.9882 - val_loss: 1.3413 - val_accuracy: 0.9777\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 47s 1s/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 1.0685 - val_accuracy: 0.9812\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 47s 1s/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.7784 - val_accuracy: 0.9783\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 47s 1s/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.5102 - val_accuracy: 0.9806\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 47s 1s/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.3566 - val_accuracy: 0.9814\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 46s 1s/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.2186 - val_accuracy: 0.9824\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 46s 1s/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.1390 - val_accuracy: 0.9828\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 45s 1s/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0901 - val_accuracy: 0.9865\n",
      "Test loss: 0.08619378507137299\n",
      "Test accuracy: 0.9864000082015991\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.33,\n",
    "          callbacks=None) #[history])\n",
    "\n",
    "#\n",
    "# Print what is in hist.history\n",
    "#\n",
    "#print('history contains: ', hist.history)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion - CNN\n",
    "The structure of my CNN is as follows: Input layer, 64 filter CNN layer with 5x5 kernal and a stride of 1,1 with RelU activation.  This is immediatly followed by a Drouput layer to turn neurons off with a rate of 50%. \n",
    "This goes into a 2x2 max pooler to reduce data which in turn goes into a second Conv layer of 128 neurons but with 5x5 stride and a 5x5 kernel. This output goes into the batch normalization function which is trainable so all of its parameters are trained automatiicly. After normalization, the data is pooled, flattened and set to the 1000 neuron Dense layer and then the output layer. Doing this the CV score was brought up to 98.86% for the finnial epoch with a test accuracy of 99.06%. This is far greater than the more complicated and longer to train Hidden layer methods above, in fact this model has only 2.2 million neurons to train. \n",
    "\n",
    "The batch size was fixed to 100 after a couple tests.  The smaller the number the longer the testing takes. At a batch of 10 the CNN took just over 1 minute per epoch, at a batch size of 1000 it took just under 30 seconds. The smaller the batch size, the more batches get run through the model so this is approproate. This also explains why with a smaller batch size the model increases its accuracy slightly \n",
    "\n",
    "A Dense layer is a fully connected layer. Atleast one is needed for the output layer that will take all of the previous neuron data and turn it into a softmax output. I use a second Dense layer right before this aswell, although it is not needed, it increases performance.\n",
    "\n",
    "Batch normalization proved to be very important to my results. It increased my resultus by about 0.5%. But I had to put one only after the second Conv layer or else  It was easy to use aswell, because the parameters were marked as Trainable so that the training algorithm will go through and train the parameters for me. \n",
    "\n",
    "A dropout is when neurons are \"turned off\" at a rate picked by me. This is a method to reduce overfitting and it works so that neurons in one layer dont co-adapt to learn off of a mistake in the previous layer. Reducing these coadaptions reduces complexity which reduces overfitting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Model Accuracy vs Epoch ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Some Predictions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.8854877e-04, 1.0100864e-03, 1.8137695e-04, 8.1075338e-04,\n",
       "        1.4034094e-05, 2.6355131e-04, 7.1966620e-06, 9.9515653e-01,\n",
       "        1.5052402e-04, 2.2175454e-03],\n",
       "       [1.5398539e-03, 1.1055869e-02, 9.8556006e-01, 3.7293491e-04,\n",
       "        1.8411743e-05, 3.2753720e-05, 7.0094148e-04, 5.1188479e-05,\n",
       "        5.9520936e-04, 7.2794865e-05],\n",
       "       [3.9578456e-04, 9.9598926e-01, 3.3922974e-04, 6.9659742e-05,\n",
       "        7.7641761e-04, 3.7614917e-04, 2.9640066e-04, 9.1565616e-04,\n",
       "        5.2868418e-04, 3.1280128e-04],\n",
       "       [9.7615677e-01, 3.8552002e-04, 1.5464196e-03, 2.1269373e-04,\n",
       "        3.5607474e-04, 4.9937743e-04, 1.6557656e-02, 4.8000255e-04,\n",
       "        1.4638560e-03, 2.3416916e-03]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict first 4 images in the test set\n",
    "print(y_test[:4])\n",
    "model.predict(x_test[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition of CIFAR-10 Images ##\n",
    "\n",
    "Here you are to design an image recognition system using this dataset.  This dataset may be loaded using the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "xtt = np.zeros(50000*32*32*1)\n",
    "xtt=xtt.reshape(x_train.shape[0], img_x, img_y, 1)\n",
    "# input image dimensions\n",
    "img_x, img_y = 32,32\n",
    "#Reshape the data into a 4d tensor\n",
    "x_train = x_train.reshape(x_train.shape[0], img_x, img_y, 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_x, img_y, 3)\n",
    "input_shape = (img_x, img_y, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 32, 32, 1)\n",
      "(10,)\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pre processing\n",
    "#Only preprocessing step is to make all images grey scale. \n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "xtt = np.mean(x_train,axis=3)\n",
    "xte = np.mean(x_test,axis=3)\n",
    "x_train=xtt.reshape(50000, img_x, img_y, 1)\n",
    "x_test=xte.reshape(10000, img_x, img_y, 1)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "\n",
    "# Data is already 255 normalized! dont do anything\n",
    "\n",
    "#print('x_train shape:', x_train.shape)\n",
    "#print(x_train.shape[0], 'train samples')\n",
    "#print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "num_classes = 10 # Number of classes\n",
    "if y_train[0].shape != (1,):\n",
    "    print('Did not increase y_train') #Put this so that data doesnt grow a dim every time it runs\n",
    "else:\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "x=y_train[0].shape \n",
    "print(x)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100  # Set the batch size\n",
    "epochs = 15 # Set the number of epochs\n",
    "num_classes=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(32,32,1)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1)))\n",
    "model.add(Dropout(rate = .01,seed = 7))\n",
    "model.add(MaxPooling2D(pool_size=(5, 5),strides=(2,2),padding='same'))\n",
    "model.add(Conv2D(60, kernel_size=(5, 5)))\n",
    "model.add(Conv2D(70, (7,7), activation='relu'))\n",
    "\n",
    "model.add(BatchNormalization(axis=3,trainable=True))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finial Model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(32,32,1)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "model.add(Dropout(rate = .01,seed = 7))\n",
    "model.add(MaxPooling2D(pool_size=(5, 5),strides=(2,2),padding='same'))\n",
    "model.add(Conv2D(64, (7,7), activation='relu'))\n",
    "\n",
    "model.add(BatchNormalization(axis=3,trainable=True))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "335/335 [==============================] - 33s 98ms/step - loss: 1.4319 - accuracy: 0.5106 - val_loss: 1.7478 - val_accuracy: 0.4730\n",
      "Epoch 2/15\n",
      "335/335 [==============================] - 32s 96ms/step - loss: 1.0191 - accuracy: 0.6471 - val_loss: 2.0190 - val_accuracy: 0.4333\n",
      "Epoch 3/15\n",
      "335/335 [==============================] - 33s 99ms/step - loss: 0.8511 - accuracy: 0.7052 - val_loss: 1.3041 - val_accuracy: 0.5780\n",
      "Epoch 4/15\n",
      "335/335 [==============================] - 33s 100ms/step - loss: 0.7050 - accuracy: 0.7545 - val_loss: 1.4744 - val_accuracy: 0.5700\n",
      "Epoch 5/15\n",
      "335/335 [==============================] - 34s 100ms/step - loss: 0.5933 - accuracy: 0.7944 - val_loss: 1.2036 - val_accuracy: 0.6270\n",
      "Epoch 6/15\n",
      "335/335 [==============================] - 33s 99ms/step - loss: 0.4795 - accuracy: 0.8331 - val_loss: 1.1673 - val_accuracy: 0.6449\n",
      "Epoch 7/15\n",
      "335/335 [==============================] - 34s 100ms/step - loss: 0.3744 - accuracy: 0.8705 - val_loss: 1.2381 - val_accuracy: 0.6584\n",
      "Epoch 8/15\n",
      "335/335 [==============================] - 33s 99ms/step - loss: 0.2783 - accuracy: 0.9044 - val_loss: 1.1632 - val_accuracy: 0.6675\n",
      "Epoch 9/15\n",
      "335/335 [==============================] - 34s 100ms/step - loss: 0.1981 - accuracy: 0.9334 - val_loss: 1.3792 - val_accuracy: 0.6690\n",
      "Epoch 10/15\n",
      "335/335 [==============================] - 34s 101ms/step - loss: 0.1419 - accuracy: 0.9547 - val_loss: 1.5879 - val_accuracy: 0.6568\n",
      "Epoch 11/15\n",
      "335/335 [==============================] - 34s 100ms/step - loss: 0.1348 - accuracy: 0.9556 - val_loss: 1.8777 - val_accuracy: 0.6139\n",
      "Epoch 12/15\n",
      "335/335 [==============================] - 34s 101ms/step - loss: 0.1264 - accuracy: 0.9563 - val_loss: 1.8257 - val_accuracy: 0.6291\n",
      "Epoch 13/15\n",
      "335/335 [==============================] - 34s 101ms/step - loss: 0.1141 - accuracy: 0.9607 - val_loss: 1.7407 - val_accuracy: 0.6612\n",
      "Epoch 14/15\n",
      "335/335 [==============================] - 34s 102ms/step - loss: 0.0960 - accuracy: 0.9670 - val_loss: 2.2355 - val_accuracy: 0.6253\n",
      "Epoch 15/15\n",
      "335/335 [==============================] - 34s 102ms/step - loss: 0.0757 - accuracy: 0.9747 - val_loss: 1.8707 - val_accuracy: 0.6723\n",
      "Test loss: 1.8940269947052002\n",
      "Test accuracy: 0.6733999848365784\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.33,\n",
    "          callbacks=None) #[history])\n",
    "\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_111 (Conv2D)          (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_88 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 9, 9, 64)          100416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_89 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 1000)              1025000   \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,136,002\n",
      "Trainable params: 1,135,874\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion - MNIST-10\n",
    "\n",
    "The only preprocessing step I did for this data set was to force the data set to be gray scale and thus 1 channel. I tried to use the RGB values and make it 3 channel, but after working through a few itterations I was unable to breka the 50% accuracy mark. \n",
    "\n",
    "\n",
    "My Model summary is shown above and I will go over the details of the model first. The model has 2 convolutional layers connected to 2 fully connected layers where the last fully connected layer is a softmax output. The first Conv layer has  a 3x3 kernal with a stride of 1 and a RelU activation. The activation proove nessacary along with the smaller 3x3 size. I initally tried using larger sizes at first, but it was better off for me to use the smaller sizes as idicated by CV scores. Next, the two convolution layers are connected with a dropout layer and a max pooling layer intbeteen. The dropout layer has a low chance (1%) to drop out, I would have expected this to improve results when higher. Having a no dropout or a higher Dropout chance reduces the CV score, so 1% was chosen.  The Max pooling was used in the previous sections so I used the same parameters from above.\n",
    "\n",
    "This feeds into the second convolutional layer which is 7x7. The larger size cuts down on parameters, increases trianing speed, and increases CV score for a triple sucess. This layer was the hardest to configure. I attempeted may different configuations with the size and number of neurons being formost consideration. I had tired larger numbers thinking that they would prove better, but I found that that was not always true and that using relativily small numbers was best. This also had the benefit of cutting down on parameters. I also expirmented with using more than 2 CNN layers, but after many attempts of trying to get 3,4 or 5 layers I found it impossible to get them to give better results than my simple 2 CNN layer model. This might be possible that since I added more layers the training took longer so to combat this I made all CNN layers smaller in neurons. I did not want processing times to go over 40 minutes for me so that I could make some progress in just a few days that I took to complete the project. \n",
    "\n",
    "After the second CNN layer I used a BatchNormalization layer. This was a boon to my accuracy and CV score. Without this layer my resutls were closer to 20% CV score. This layer was easy to use becasue it trained its own parameters, but because of this I did extend the number of Epochs from 10 to 15 that the model had more time to stabilze. The location of the layer mattered a great deal. I could not add a BatchNorm layer after the other CNN, doing so caused harm. I can only theorize that perhaps some small number of batches created extremly weird outpus of the first CNN layer so normalization made other batches have similar defects.\n",
    "\n",
    "The finial layers were a max_pooling layer configured as above followed by a flatten into the two dense layers that were configued and discussed at length in the first part of this project. \n",
    "\n",
    "Doing all of this I was able to get a system with a CV score of 67.23% and a testing accuracy of 67.33%. The training accuracy is 98% so there is clearly overfitting occuring, but the methods I have researched to remove this revolve around more data or other methods that extend processing time. I thought that with the simple nature of my CNN,having just 1.1 million parameters, the results were inspiring. My first step to increase results would be to up the number of Epochs. Going from 10 to 15 with the current model improved accuracy by 7% so at 15 there is still imporovment to be had. It is a time consuming imporovemnt so I did not worry for the purpose of this project. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
